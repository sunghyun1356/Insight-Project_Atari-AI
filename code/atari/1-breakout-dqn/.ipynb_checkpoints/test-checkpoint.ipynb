{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ed516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태가 입력, 큐함수가 출력인 인공신경망 생성\n",
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, action_size, state_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = Conv2D(32, (8, 8), strides=(4, 4), activation='relu',\n",
    "                            input_shape=state_size)\n",
    "        self.conv2 = Conv2D(64, (4, 4), strides=(2, 2), activation='relu')\n",
    "        self.conv3 = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.fc = Dense(512, activation='relu')\n",
    "        self.fc_out = Dense(action_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        q = self.fc_out(x)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07113200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브레이크아웃 예제에서의 DQN 에이전트\n",
    "class DQNAgent:\n",
    "    def __init__(self, action_size, state_size, model_path):\n",
    "        self.render = False\n",
    "\n",
    "        # 상태와 행동의 크기 정의\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        self.epsilon = 0.02\n",
    "\n",
    "        # 모델과 타깃 모델 생성\n",
    "        self.model = DQN(action_size, state_size)\n",
    "        self.model.load_weights(model_path)\n",
    "\n",
    "    # 입실론 탐욕 정책으로 행동 선택\n",
    "    def get_action(self, history):\n",
    "        history = np.float32(history / 255.0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model(history)\n",
    "            return np.argmax(q_value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96627fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(observe):\n",
    "    processed_observe = np.uint8(\n",
    "        resize(rgb2gray(observe), (84, 84), mode='constant') * 255)\n",
    "    return processed_observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 환경 세팅\n",
    "    env = gym.make(\"BreakoutDeterministic-v4\")\n",
    "    render = True\n",
    "\n",
    "    # 테스트를 위한 에이전트 생성\n",
    "    state_size = (84, 84, 4)\n",
    "    action_size = 3\n",
    "    model_path = './save_model/trained/model'\n",
    "    agent = DQNAgent(action_size, state_size, model_path)\n",
    "\n",
    "    # 불필요한 행동을 없애주기 위한 딕셔너리 선언\n",
    "    action_dict = {0:1, 1:2, 2:3, 3:3}\n",
    "\n",
    "    num_episode = 10\n",
    "    for e in range(num_episode):\n",
    "        done = False\n",
    "        dead = False\n",
    "\n",
    "        score, start_life = 0, 5\n",
    "        # env 초기화\n",
    "        observe = env.reset()\n",
    "\n",
    "        # 랜덤으로 뽑힌 값 만큼의 프레임동안 움직이지 않음\n",
    "        for _ in range(random.randint(1, 30)):\n",
    "            observe, _, _, _ = env.step(1)\n",
    "\n",
    "        # 프레임을 전처리 한 후 4개의 상태를 쌓아서 입력값으로 사용.\n",
    "        state = pre_processing(observe)\n",
    "        history = np.stack([state, state, state, state], axis=2)\n",
    "        history = np.reshape([history], (1, 84, 84, 4))\n",
    "\n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(0.05)\n",
    "\n",
    "            # 바로 전 history를 입력으로 받아 행동을 선택\n",
    "            action = agent.get_action(history)\n",
    "            # 1: 정지, 2: 왼쪽, 3: 오른쪽\n",
    "            real_action = action_dict[action]\n",
    "            \n",
    "            # 죽었을 때 시작하기 위해 발사 행동을 함\n",
    "            if dead:\n",
    "                action, real_action, dead = 0, 1, False\n",
    "\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
    "            observe, reward, done, info = env.step(real_action)\n",
    "            # 각 타임스텝마다 상태 전처리\n",
    "            next_state = pre_processing(observe)\n",
    "            next_state = np.reshape([next_state], (1, 84, 84, 1))\n",
    "            next_history = np.append(next_state, history[:, :, :, :3], axis=3)\n",
    "\n",
    "            if start_life > info['lives']:\n",
    "                dead, start_life = True, info['lives']\n",
    "\n",
    "            score += reward\n",
    "\n",
    "            if dead:\n",
    "                history = np.stack((next_state, next_state,\n",
    "                                    next_state, next_state), axis=2)\n",
    "                history = np.reshape([history], (1, 84, 84, 4))\n",
    "            else:\n",
    "                history = next_history\n",
    "\n",
    "            if done:\n",
    "                # 각 에피소드 당 테스트 정보를 기록\n",
    "                print(\"episode: {:3d} | score : {:4.1f}\".format(e, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3ba33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
